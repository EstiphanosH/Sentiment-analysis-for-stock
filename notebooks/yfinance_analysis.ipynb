{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from scripts.eda_analysis import InteractiveDataAnalyzer\n",
    "from scripts.time_series_analysis import TimeSeriesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Download data for multiple tickers\n",
    "tickers = [\"AAPL\", \"AMZN\", \"GOOG\", \"META\", \"MSFT\", \"NVDA\", \"TSLA\"]\n",
    "data = {}\n",
    "for ticker in tickers:\n",
    "    df = yf.download(tickers=ticker, start=\"2000-01-01\", end=\"2024-12-31\", interval=\"1d\")\n",
    "    data[ticker] = df\n",
    "    print(f\"{ticker} Head:\\n\", df.head(5), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Save each ticker's data to a CSV file\n",
    "save_dir = \"../data/raw/downloaded\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "for ticker, df in data.items():\n",
    "    filename = f\"{ticker}_yfdata_download.csv\"\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "    df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load saved CSVs for EDA and time series analysis\n",
    "import glob\n",
    "\n",
    "csv_files = glob.glob(os.path.join(save_dir, \"*_yfdata_download.csv\"))\n",
    "downloaded_data = {}\n",
    "for file in csv_files:\n",
    "    ticker = os.path.basename(file).split(\"_\")[0]\n",
    "    try:\n",
    "        # Always load with index_col=0 (yfinance saves date as index)\n",
    "        df = pd.read_csv(file, index_col=0)\n",
    "        if df.empty:\n",
    "            print(f\"❌ {ticker}: File is empty, skipping.\")\n",
    "            continue\n",
    "        # Convert index to datetime and reset as column\n",
    "        df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "        df = df.reset_index()\n",
    "        # Ensure the date column is named 'Date'\n",
    "        if 'index' in df.columns:\n",
    "            df = df.rename(columns={'index': 'Date'})\n",
    "        elif 'Date' not in df.columns:\n",
    "            df = df.rename(columns={df.columns[0]: 'Date'})\n",
    "        # Drop rows where Date could not be parsed\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        # Ensure Date column is datetime\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        downloaded_data[ticker] = df\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load {ticker}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. EDA Analysis for each ticker\n",
    "for ticker, df in downloaded_data.items():\n",
    "    print(f\"\\n--- EDA for {ticker} ---\")\n",
    "    try:\n",
    "        eda = InteractiveDataAnalyzer(df)\n",
    "        eda.interactive_summary(save_pdf=True, pdf_path=f\"eda_{ticker}_yf.pdf\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ EDA failed for {ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Time Series Analysis for each ticker\n",
    "for ticker, df in downloaded_data.items():\n",
    "    print(f\"\\n--- Time Series Analysis for {ticker} ---\")\n",
    "    try:\n",
    "        tsa = TimeSeriesAnalyzer(\n",
    "            data=df,\n",
    "            date_col='Date',\n",
    "            value_col='Close',\n",
    "            open_col='Open',\n",
    "            high_col='High',\n",
    "            low_col='Low',\n",
    "            volume_col='Volume'\n",
    "        )\n",
    "        tsa.plot_series(title=f\"{ticker} Close Price Time Series\")\n",
    "        tsa.plot_decomposition(freq=252)\n",
    "        stationarity = tsa.test_stationarity()\n",
    "        print(\"ADF Test:\", stationarity['ADF'])\n",
    "        print(\"KPSS Test:\", stationarity['KPSS'])\n",
    "        tsa.plot_acf_pacf(lags=40)\n",
    "        indicators = tsa.calculate_technical_indicators()\n",
    "        print(\"✅ Technical indicators calculated\")\n",
    "        display(indicators.tail())\n",
    "        model_fit = tsa.fit_arima(order=(1, 1, 1))\n",
    "        tsa.forecast(steps=30)\n",
    "        tsa.save_summary_pdf(pdf_path=f\"tsa_summary_{ticker}_yf.pdf\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Time series analysis failed for {ticker}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
